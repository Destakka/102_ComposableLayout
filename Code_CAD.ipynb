{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6uBVaVzMhaztfzVhE99m0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Destakka/102_ComposableLayout/blob/master/Code_CAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNetB1#"
      ],
      "metadata": {
        "id": "mfUyQSOjAHMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeLpWx-p_5-L"
      },
      "outputs": [],
      "source": [
        "# **bold text**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "import re, glob\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "im_size = 224\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Training_images'\n",
        "dirs = os.listdir(PATH) #list directory in Land Use Images folder\n",
        "label = 0\n",
        "im_arr = []\n",
        "lb_arr = []\n",
        "X = []\n",
        "y = []\n",
        "for folder in dirs:\n",
        "    folder_path = os.path.join(PATH, folder)  # Pastikan path benar\n",
        "    if os.path.isdir(folder_path):  # Hanya proses jika path adalah folder\n",
        "        count = 0\n",
        "        for pic in glob.glob(folder_path + '/*'):  # Cari semua file di folder\n",
        "            im = cv2.imread(pic)  # Baca gambar\n",
        "            im = cv2.resize(im, (im_size, im_size))  # Resize ke 224x224\n",
        "            im = np.array(im)  # Ubah jadi array\n",
        "            count += 1\n",
        "            X.append(im)  # Tambah ke array X\n",
        "            y.append(label)  # Tambah label\n",
        "            if count <= 7:  # Hanya untuk contoh\n",
        "                im_arr.append({str(folder): im})\n",
        "        print(f\"Jumlah {folder}: {count}\")\n",
        "        label += 1\n",
        "        lb_arr.append(folder)\n",
        "\n",
        "# Konversi X dan y ke numpy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"--- {time.time() - start_time} seconds ---\")\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualisasi gambar dari im_arr\n",
        "fig, axs = plt.subplots(2, 7, figsize=(20, 10))  # Grid 2x7 untuk 14 gambar\n",
        "cnt = 0\n",
        "for row in range(2):\n",
        "    for col in range(7):\n",
        "        if cnt < len(im_arr):  # Pastikan tidak melebihi jumlah gambar di im_arr\n",
        "            for key, value in im_arr[cnt].items():\n",
        "                axs[row, col].imshow(value)\n",
        "                axs[row, col].set_title(key)\n",
        "                axs[row, col].axis('off')  # Hilangkan axis\n",
        "            cnt += 1\n",
        "        else:\n",
        "            axs[row, col].axis('off')  # Kosongkan plot jika tidak ada gambar\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "TEST_PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Test_images'  # Ganti dengan path folder data test Anda\n",
        "TRAIN_PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Training_images'\n",
        "VALID_PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Validation_images' # Path untuk data validasi\n",
        "#TEST_PATH = '/content/drive/MyDrive/BARU/Test/'\n",
        "\n",
        "#X_test = []\n",
        "#y_test = []\n",
        "#label = 0\n",
        "\n",
        "#for i in os.listdir(TEST_PATH):\n",
        "    #for pic in glob.glob(TEST_PATH + i + '/*'):\n",
        "        #im = cv2.imread(pic)\n",
        "        #im = cv2.resize(im, (im_size, im_size))\n",
        "        #im = np.array(im)\n",
        "        #X_test.append(im)\n",
        "        #y_test.append(label)\n",
        "    #label = label + 1\n",
        "def load_and_preprocess_data(data_path, im_size=224):\n",
        "    X = []\n",
        "    y = []\n",
        "    label = 0\n",
        "    for folder in os.listdir(data_path):  # Loop melalui folder di data_path\n",
        "        folder_path = os.path.join(data_path, folder)\n",
        "        if os.path.isdir(folder_path):  # Pastikan hanya memproses folder\n",
        "            for pic in glob.glob(folder_path + '/*'):\n",
        "                im = cv2.imread(pic)  # Baca gambar\n",
        "                im = cv2.resize(im, (im_size, im_size))  # Resize ke im_size x im_size\n",
        "                im = np.array(im)  # Ubah jadi array numpy\n",
        "                X.append(im)  # Tambahkan gambar ke X\n",
        "                y.append(label)  # Tambahkan label ke y\n",
        "            label += 1  # Perbarui label untuk folder berikutnya\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Contoh penggunaan\n",
        "X_train, y_train = load_and_preprocess_data(TRAIN_PATH)\n",
        "X_test, y_test = load_and_preprocess_data(TEST_PATH)\n",
        "X_valid, y_valid = load_and_preprocess_data(VALID_PATH)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}, Labels shape: {y_test.shape}\")\n",
        "print(f\"Validation data shape: {X_valid.shape}, Labels shape: {y_valid.shape}\")\n",
        "X_train, y_train = load_and_preprocess_data(TRAIN_PATH)\n",
        "X_val, y_val = load_and_preprocess_data(VALID_PATH)\n",
        "X_test, y_test = load_and_preprocess_data(TEST_PATH)\n",
        "# PREPROCESSING\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rasio split data\n",
        "train_ratio = 0.70\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.20\n",
        "\n",
        "# Split data menjadi train, validation, dan test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - train_ratio), random_state=5)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(test_ratio / (test_ratio + validation_ratio)), random_state=1)\n",
        "\n",
        "# Konversi tipe data ke float32\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "# Normalisasi data (ubah nilai menjadi antara 0 dan 1)\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "X_val /= 255.0\n",
        "\n",
        "# One-hot encoding untuk label\n",
        "y_train = to_categorical(y_train, num_classes=len(np.unique(y)))\n",
        "y_val = to_categorical(y_val, num_classes=len(np.unique(y)))\n",
        "y_test = to_categorical(y_test, num_classes=len(np.unique(y)))\n",
        "\n",
        "# Data augmentation menggunakan ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Informasi data\n",
        "print(f\"Data Latih : {len(X_train)}\")\n",
        "print(f\"Data Uji : {len(X_test)}\")\n",
        "print(f\"Data Validasi : {len(X_val)}\")\n",
        "from tensorflow.keras.applications import ConvNeXtTiny # Import the ConvNeXtTiny class\n",
        "\n",
        "# Load the ConvNeXtTiny model\n",
        "efficientnet_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
        "#x = resnet_model.layers[-2].output\n",
        "#dropOutCus = Dropout(0.5)(x)\n",
        "#output = Dense(units=2, activation='softmax')(dropOutCus)\n",
        "\n",
        "#efficientnet_model = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
        "\n",
        "x = efficientnet_model.output  # Output dari EfficientNetB1\n",
        "x = Flatten()(x)  # Tambahkan lapisan Flatten untuk mengubah output 4D menjadi 2D\n",
        "dropOutCus = Dropout(0.5)(x)  # Dropout untuk mencegah overfitting\n",
        "output = Dense(units=2, activation='softmax')(dropOutCus)  # Output layer dengan 2 kelas dan aktivasi softmax\n",
        "model = keras.Model(inputs=efficientnet_model.input, outputs=output)  # Buat model dengan EfficientNetB1\n",
        "\n",
        "# Bekukan 100 lapisan pertama dari ConvNeXtTiny untuk transfer learning\n",
        "for layer in efficientnet_model.layers[:50]:  # Bekukan 100 lapisan pertama EfficientNetB1\n",
        "    layer.trainable = False\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Fungsi scheduler untuk mengatur learning rate\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))  # Exponential decay setelah 10 epoch\n",
        "lr_scheduler = LearningRateScheduler(scheduler, verbose=1)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# TRAINING\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=25,  # Tingkatkan epoch untuk eksplorasi, EarlyStopping akan menghentikan pelatihan lebih awal\n",
        "    batch_size=32,\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluasi model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Accuracy: {scores[1] * 100:.2f}%\")\n",
        "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'],'r',label='training loss')\n",
        "plt.plot(history.history['val_loss'],label='validation loss')\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "los = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['accuracy'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Training accuracy'))\n",
        "fig.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['val_accuracy'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Validation accuracy'))\n",
        "fig.update_layout(title='Accuracy',\n",
        "                  xaxis=dict(title='Epoch'),\n",
        "                  yaxis=dict(title='Percentage'))\n",
        "\n",
        "los.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['loss'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Training loss'))\n",
        "los.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['val_loss'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Validation loss'))\n",
        "los.update_layout(title='Loss',\n",
        "                  xaxis=dict(title='Epoch'),\n",
        "                  yaxis=dict(title='Percentage'))\n",
        "\n",
        "fig.show()\n",
        "los.show()\n",
        "\n",
        "# Evaluasi akurasi model\n",
        "accuracy = scores[1] * 100  # Mengambil skor akurasi dari hasil evaluasi\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Prediksi data uji\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(true_classes), yticklabels=np.unique(true_classes))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(true_classes, predicted_classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ConvNextTiny#\n"
      ],
      "metadata": {
        "id": "rsfT8mcNAdGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **bold text**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "import re, glob\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "im_size = 224\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Training_images'\n",
        "dirs = os.listdir(PATH) #list directory in Land Use Images folder\n",
        "label = 0\n",
        "im_arr = []\n",
        "lb_arr = []\n",
        "X = []\n",
        "y = []\n",
        "for folder in dirs:\n",
        "    folder_path = os.path.join(PATH, folder)  # Pastikan path benar\n",
        "    if os.path.isdir(folder_path):  # Hanya proses jika path adalah folder\n",
        "        count = 0\n",
        "        for pic in glob.glob(folder_path + '/*'):  # Cari semua file di folder\n",
        "            im = cv2.imread(pic)  # Baca gambar\n",
        "            im = cv2.resize(im, (im_size, im_size))  # Resize ke 224x224\n",
        "            im = np.array(im)  # Ubah jadi array\n",
        "            count += 1\n",
        "            X.append(im)  # Tambah ke array X\n",
        "            y.append(label)  # Tambah label\n",
        "            if count <= 7:  # Hanya untuk contoh\n",
        "                im_arr.append({str(folder): im})\n",
        "        print(f\"Jumlah {folder}: {count}\")\n",
        "        label += 1\n",
        "        lb_arr.append(folder)\n",
        "\n",
        "# Konversi X dan y ke numpy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"--- {time.time() - start_time} seconds ---\")\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualisasi gambar dari im_arr\n",
        "fig, axs = plt.subplots(2, 7, figsize=(20, 10))  # Grid 2x7 untuk 14 gambar\n",
        "cnt = 0\n",
        "for row in range(2):\n",
        "    for col in range(7):\n",
        "        if cnt < len(im_arr):  # Pastikan tidak melebihi jumlah gambar di im_arr\n",
        "            for key, value in im_arr[cnt].items():\n",
        "                axs[row, col].imshow(value)\n",
        "                axs[row, col].set_title(key)\n",
        "                axs[row, col].axis('off')  # Hilangkan axis\n",
        "            cnt += 1\n",
        "        else:\n",
        "            axs[row, col].axis('off')  # Kosongkan plot jika tidak ada gambar\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "TEST_PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Test_images'  # Ganti dengan path folder data test Anda\n",
        "TRAIN_PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Training_images'\n",
        "VALID_PATH = '/content/drive/MyDrive/Comvis/Dataset Comvis/Validation_images' # Path untuk data validasi\n",
        "#TEST_PATH = '/content/drive/MyDrive/BARU/Test/'\n",
        "\n",
        "#X_test = []\n",
        "#y_test = []\n",
        "#label = 0\n",
        "\n",
        "#for i in os.listdir(TEST_PATH):\n",
        "    #for pic in glob.glob(TEST_PATH + i + '/*'):\n",
        "        #im = cv2.imread(pic)\n",
        "        #im = cv2.resize(im, (im_size, im_size))\n",
        "        #im = np.array(im)\n",
        "        #X_test.append(im)\n",
        "        #y_test.append(label)\n",
        "    #label = label + 1\n",
        "def load_and_preprocess_data(data_path, im_size=224):\n",
        "    X = []\n",
        "    y = []\n",
        "    label = 0\n",
        "    for folder in os.listdir(data_path):  # Loop melalui folder di data_path\n",
        "        folder_path = os.path.join(data_path, folder)\n",
        "        if os.path.isdir(folder_path):  # Pastikan hanya memproses folder\n",
        "            for pic in glob.glob(folder_path + '/*'):\n",
        "                im = cv2.imread(pic)  # Baca gambar\n",
        "                im = cv2.resize(im, (im_size, im_size))  # Resize ke im_size x im_size\n",
        "                im = np.array(im)  # Ubah jadi array numpy\n",
        "                X.append(im)  # Tambahkan gambar ke X\n",
        "                y.append(label)  # Tambahkan label ke y\n",
        "            label += 1  # Perbarui label untuk folder berikutnya\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Contoh penggunaan\n",
        "X_train, y_train = load_and_preprocess_data(TRAIN_PATH)\n",
        "X_test, y_test = load_and_preprocess_data(TEST_PATH)\n",
        "X_valid, y_valid = load_and_preprocess_data(VALID_PATH)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}, Labels shape: {y_test.shape}\")\n",
        "print(f\"Validation data shape: {X_valid.shape}, Labels shape: {y_valid.shape}\")\n",
        "X_train, y_train = load_and_preprocess_data(TRAIN_PATH)\n",
        "X_val, y_val = load_and_preprocess_data(VALID_PATH)\n",
        "X_test, y_test = load_and_preprocess_data(TEST_PATH)\n",
        "# PREPROCESSING\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rasio split data\n",
        "train_ratio = 0.70\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.20\n",
        "\n",
        "# Split data menjadi train, validation, dan test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - train_ratio), random_state=5)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(test_ratio / (test_ratio + validation_ratio)), random_state=1)\n",
        "\n",
        "# Konversi tipe data ke float32\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "# Normalisasi data (ubah nilai menjadi antara 0 dan 1)\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "X_val /= 255.0\n",
        "\n",
        "# One-hot encoding untuk label\n",
        "y_train = to_categorical(y_train, num_classes=len(np.unique(y)))\n",
        "y_val = to_categorical(y_val, num_classes=len(np.unique(y)))\n",
        "y_test = to_categorical(y_test, num_classes=len(np.unique(y)))\n",
        "\n",
        "# Data augmentation menggunakan ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Informasi data\n",
        "print(f\"Data Latih : {len(X_train)}\")\n",
        "print(f\"Data Uji : {len(X_test)}\")\n",
        "print(f\"Data Validasi : {len(X_val)}\")\n",
        "from tensorflow.keras.applications import ConvNeXtTiny # Import the ConvNeXtTiny class\n",
        "\n",
        "# Load the ConvNeXtTiny model\n",
        "convnext_model = ConvNeXtTiny(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
        "#x = resnet_model.layers[-2].output\n",
        "#dropOutCus = Dropout(0.5)(x)\n",
        "#output = Dense(units=2, activation='softmax')(dropOutCus)\n",
        "\n",
        "#efficientnet_model = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
        "\n",
        "x = convnext_model.output  # Output dari EfficientNetB1\n",
        "x = Flatten()(x)  # Tambahkan lapisan Flatten untuk mengubah output 4D menjadi 2D\n",
        "dropOutCus = Dropout(0.5)(x)  # Dropout untuk mencegah overfitting\n",
        "output = Dense(units=2, activation='softmax')(dropOutCus)  # Output layer dengan 2 kelas dan aktivasi softmax\n",
        "model = keras.Model(inputs=convnext_model.input, outputs=output)  # Buat model dengan EfficientNetB1\n",
        "\n",
        "# Bekukan 100 lapisan pertama dari ConvNeXtTiny untuk transfer learning\n",
        "for layer in convnext_model.layers[:50]:  # Bekukan 100 lapisan pertama EfficientNetB1\n",
        "    layer.trainable = False\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Fungsi scheduler untuk mengatur learning rate\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))  # Exponential decay setelah 10 epoch\n",
        "lr_scheduler = LearningRateScheduler(scheduler, verbose=1)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# TRAINING\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=25,  # Tingkatkan epoch untuk eksplorasi, EarlyStopping akan menghentikan pelatihan lebih awal\n",
        "    batch_size=32,\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluasi model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Accuracy: {scores[1] * 100:.2f}%\")\n",
        "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'],'r',label='training loss')\n",
        "plt.plot(history.history['val_loss'],label='validation loss')\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "los = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['accuracy'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Training accuracy'))\n",
        "fig.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['val_accuracy'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Validation accuracy'))\n",
        "fig.update_layout(title='Accuracy',\n",
        "                  xaxis=dict(title='Epoch'),\n",
        "                  yaxis=dict(title='Percentage'))\n",
        "\n",
        "los.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['loss'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Training loss'))\n",
        "los.add_trace(go.Scatter(x=history.epoch,\n",
        "                         y=history.history['val_loss'],\n",
        "                         mode='lines+markers',\n",
        "                         name='Validation loss'))\n",
        "los.update_layout(title='Loss',\n",
        "                  xaxis=dict(title='Epoch'),\n",
        "                  yaxis=dict(title='Percentage'))\n",
        "\n",
        "fig.show()\n",
        "los.show()\n",
        "\n",
        "# Evaluasi akurasi model\n",
        "accuracy = scores[1] * 100  # Mengambil skor akurasi dari hasil evaluasi\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Prediksi data uji\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(true_classes), yticklabels=np.unique(true_classes))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(true_classes, predicted_classes))\n"
      ],
      "metadata": {
        "id": "Wqd5LXv7AAa5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}